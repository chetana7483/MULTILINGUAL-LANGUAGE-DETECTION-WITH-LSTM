import wikipediaapi
import pandas as pd
import re
import time
import random

languages = {
    "en": {"name": "English", "topics": ["India", "Science", "Technology", "Education", "Culture"]},
    "kn": {"name": "Kannada", "topics": ["‡≤≠‡≤æ‡≤∞‡≤§", "‡≤µ‡≤ø‡≤ú‡≥ç‡≤û‡≤æ‡≤®", "‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤®", "‡≤∂‡≤ø‡≤ï‡≥ç‡≤∑‡≤£", "‡≤∏‡≤Ç‡≤∏‡≥ç‡≤ï‡≥É‡≤§‡≤ø"]},
    "ta": {"name": "Tamil", "topics": ["‡Æá‡Æ®‡Øç‡Æ§‡Æø‡ÆØ‡Ææ", "‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç", "‡Æ§‡Øä‡Æ¥‡Æø‡Æ≤‡Øç‡Æ®‡ØÅ‡Æü‡Øç‡Æ™‡ÆÆ‡Øç", "‡Æï‡Æ≤‡Øç‡Æµ‡Æø", "‡Æï‡Æ≤‡Øà"]},
    "hi": {"name": "Hindi", "topics": ["‡§≠‡§æ‡§∞‡§§", "‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®", "‡§á‡§§‡§ø‡§π‡§æ‡§∏", "‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø", "‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä", "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ", "‡§≠‡§æ‡§∞‡§§_‡§ï‡§æ_‡§á‡§§‡§ø‡§π‡§æ‡§∏"]}
}

USER_AGENT = "MiniLangCollector/1.0 (contact: your_email@example.com)"
data = []

for lang_code, info in languages.items():
    wiki = wikipediaapi.Wikipedia(language=lang_code, user_agent=USER_AGENT)
    sentences = []

    print(f"\nüîç Collecting {info['name']} sentences...")

    for topic in info["topics"]:
        try:
            page = wiki.page(topic)
            if not page.exists():
                continue

            text = re.sub(r'\n+', ' ', page.text)
            sents = re.split(r'(?<=[.!?‡•§]) +', text)  # added Hindi full stop '‡•§'

            for s in sents:
                if 10 <= len(s) <= 200:
                    sentences.append(s.strip())
                if len(sentences) >= 100:
                    break
            if len(sentences) >= 100:
                break
            time.sleep(2)

        except Exception as e:
            print(f"‚ö†Ô∏è Error fetching topic '{topic}' for {info['name']}: {e}")
            continue

    if len(sentences) == 0:
        print(f"‚ö†Ô∏è No sentences found for {info['name']}!")
    else:
        print(f"‚úÖ Collected {len(sentences)} {info['name']} sentences.")

    for s in sentences:
        data.append([s, info["name"]])

df = pd.DataFrame(data, columns=['text', 'language'])
df.to_csv("mini_multilingual.csv", index=False, encoding='utf-8')

print("\n‚úÖ Dataset created successfully with shape:", df.shape)
 